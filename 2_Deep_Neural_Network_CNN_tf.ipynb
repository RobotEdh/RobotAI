{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages\n",
    "\n",
    "Let's first import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the main package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n",
    "- dnn_utils provides some necessary functions for this notebook.\n",
    "- testCases provides some test cases to assess the correctness of your functions\n",
    "- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work. Please don't change the seed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Eager execution: True\n",
      "scipy version: 1.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"scipy version: {}\".format(scipy.__version__))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_CNN_2layers():\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_seed(1)\n",
    "    parameters = {}\n",
    "    listp = []  \n",
    "    \n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed = 0)\n",
    "    parameters['W1'] = tf.Variable( initializer( shape=(4, 4, 3, 8), dtype=tf.dtypes.float32))\n",
    "    parameters['W2'] = tf.Variable( initializer( shape=(2, 2, 8, 16), dtype=tf.dtypes.float32))\n",
    "    parameters['W3'] = tf.Variable( initializer( shape=(6,64), dtype=tf.dtypes.float32))\n",
    "                                               \n",
    "\n",
    "    for l in range(1, 4): \n",
    "            listp.append(parameters[\"W\"+str(l)])\n",
    "\n",
    "    \n",
    "    return listp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Variable:0' shape=(4, 4, 3, 8) dtype=float32, numpy=\n",
      "array([[[[-0.2056607    , -0.058337234  , -0.08025538   ,\n",
      "           0.010544738  , -0.032211605  ,  0.010961418  ,\n",
      "          -0.10336155   ,  0.08746794   ],\n",
      "         [ 0.20160557   , -0.014191296  ,  0.046245974  ,\n",
      "           0.05640402   , -0.07115588   , -0.004663535  ,\n",
      "          -0.071886525  ,  0.04198296   ],\n",
      "         [ 0.11124081   ,  0.03141133   , -0.13370019   ,\n",
      "          -0.16261466   ,  0.11981839   , -0.03923665   ,\n",
      "           0.16329722   ,  0.12666985   ]],\n",
      "\n",
      "        [[-0.15021932   ,  0.1304466    ,  0.13095827   ,\n",
      "           0.037389427  ,  0.009515136  ,  0.06832766   ,\n",
      "          -0.055537704  ,  0.079958804  ],\n",
      "         [ 0.1026027    , -0.1641346    , -0.015676552  ,\n",
      "          -0.16435538   , -0.030360183  , -0.017152643  ,\n",
      "          -0.15462536   ,  0.046536155  ],\n",
      "         [ 0.11646616   ,  0.037236407  , -0.051597413  ,\n",
      "          -0.050739672  , -0.23097187   , -0.055465907  ,\n",
      "           0.17333788   ,  0.028046163  ]],\n",
      "\n",
      "        [[-0.07641366   ,  0.07721653   , -0.03142853   ,\n",
      "          -0.16115956   ,  0.020791944  ,  0.10269987   ,\n",
      "           0.17428814   ,  0.085962206  ],\n",
      "         [-0.13051225   , -0.068799816  ,  0.13428038   ,\n",
      "          -0.07654791   , -0.008106751  , -0.17554323   ,\n",
      "           0.11249421   , -0.24038349   ],\n",
      "         [-0.0249727    ,  0.1296663    ,  0.14272101   ,\n",
      "          -0.039612755  , -0.14581119   ,  0.2307103    ,\n",
      "           0.050366078  ,  0.076432675  ]],\n",
      "\n",
      "        [[-0.13772303   , -0.100143984  , -0.0025116305 ,\n",
      "          -0.09306639   ,  0.02259189   , -0.04495305   ,\n",
      "          -0.024159303  , -0.12152702   ],\n",
      "         [ 0.054739475  ,  0.07112456   ,  0.0306984    ,\n",
      "           0.04707698   , -0.053055294  ,  0.0219482    ,\n",
      "           0.080069296  , -0.026258497  ],\n",
      "         [-0.061444532  ,  0.16244145   ,  0.055342246  ,\n",
      "           0.06501737   ,  0.00062157726, -0.16963594   ,\n",
      "           0.054063626  , -0.070211925  ]]],\n",
      "\n",
      "\n",
      "       [[[-0.08404473   , -0.017487185  , -0.13100289   ,\n",
      "           0.15567303   ,  0.01919506   , -0.07135578   ,\n",
      "          -0.09526822   ,  0.09706312   ],\n",
      "         [-0.16427642   , -0.11239476   ,  0.0003032369 ,\n",
      "          -0.013954712  , -0.08558976   ,  0.032745898  ,\n",
      "           0.05696607   ,  0.012038812  ],\n",
      "         [ 0.01656274   , -0.15432547   , -0.06132456   ,\n",
      "          -0.107333146  ,  0.12268902   , -0.120681226  ,\n",
      "           0.091555886  , -0.029395154  ]],\n",
      "\n",
      "        [[-0.042396713  ,  0.09286223   ,  0.11703825   ,\n",
      "          -0.09484164   ,  0.09906754   ,  0.03928805   ,\n",
      "           0.025922913  , -0.12450745   ],\n",
      "         [ 0.033938494  , -0.16554174   , -0.006312997  ,\n",
      "           0.018527476  , -0.033017788  , -0.03344928   ,\n",
      "          -0.14225453   ,  0.13832784   ],\n",
      "         [-0.07885145   , -0.11165178   , -0.083606474  ,\n",
      "          -0.037195534  , -0.065228894  ,  0.044837486  ,\n",
      "           0.008512022  ,  0.014908531  ]],\n",
      "\n",
      "        [[-0.19324785   , -0.019002229  ,  0.06773087   ,\n",
      "          -0.101605274  , -0.0713296    ,  0.08724922   ,\n",
      "          -0.036795396  , -0.036270004  ],\n",
      "         [-0.24118762   , -0.008140767  ,  0.17303337   ,\n",
      "          -0.012568133  , -0.0608417    ,  0.053899728  ,\n",
      "           0.07218674   ,  0.0956345    ],\n",
      "         [-0.022760913  , -0.004913382  ,  0.051265277  ,\n",
      "           0.049139746  ,  0.23612286   ,  0.1581947    ,\n",
      "           0.021141527  ,  0.15780354   ]],\n",
      "\n",
      "        [[ 0.08804657   ,  0.083803676  , -0.13135408   ,\n",
      "           0.09140036   ,  0.122488715  , -0.14169648   ,\n",
      "          -0.024129063  , -0.0557438    ],\n",
      "         [ 0.01842761   , -0.053333215  , -0.16004707   ,\n",
      "          -0.06551287   ,  0.06252042   ,  0.16118719   ,\n",
      "          -0.017118564  ,  0.023956347  ],\n",
      "         [-0.034100596  ,  0.049872745  ,  0.07815102   ,\n",
      "           0.043634016  ,  0.23563786   , -0.038028724  ,\n",
      "           0.15337384   , -0.03258593   ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.06902518   , -0.018053176  ,  0.121757396  ,\n",
      "           0.02626888   ,  0.014287468  , -0.027060505  ,\n",
      "           0.16283856   ,  0.053874794  ],\n",
      "         [ 0.06827045   ,  0.033536255  , -0.04978821   ,\n",
      "           0.003266737  , -0.023201581  , -0.17791864   ,\n",
      "           0.12607764   ,  0.045136765  ],\n",
      "         [ 0.11060735   , -0.1511999    ,  0.07841083   ,\n",
      "           0.07825499   ,  0.06769789   ,  0.12353288   ,\n",
      "           0.015010903  ,  0.104386024  ]],\n",
      "\n",
      "        [[ 0.18075043   , -0.14717397   , -0.0048290286 ,\n",
      "          -0.10127829   ,  0.09488864   , -0.11086895   ,\n",
      "          -0.13279039   ,  0.07625383   ],\n",
      "         [ 0.11456253   ,  0.008346597  , -0.03475867   ,\n",
      "          -0.037457887  , -0.20860933   ,  0.11547194   ,\n",
      "          -0.05956051   , -0.08077987   ],\n",
      "         [-0.07590048   ,  0.010003367  , -0.18179272   ,\n",
      "           0.054977834  , -0.1498076    , -0.16539796   ,\n",
      "           0.15784423   ,  0.10997067   ]],\n",
      "\n",
      "        [[ 0.07416656   , -0.05297015   ,  0.10579437   ,\n",
      "           0.06478726   , -0.03480508   ,  0.04093305   ,\n",
      "          -0.06251876   , -0.23357105   ],\n",
      "         [ 0.0019826568 ,  0.060724765  , -0.13359284   ,\n",
      "          -0.04554868   ,  0.016410911  ,  0.12910013   ,\n",
      "          -0.143667     ,  0.10251446   ],\n",
      "         [ 0.11290423   ,  0.096569315  , -0.072109595  ,\n",
      "          -0.09339685   , -0.08295616   , -0.012519034  ,\n",
      "          -0.22242972   ,  0.20193967   ]],\n",
      "\n",
      "        [[-0.055391654  , -0.004790014  , -0.08380027   ,\n",
      "           0.08814912   , -0.021269493  ,  0.09094029   ,\n",
      "           0.07852046   , -0.10663234   ],\n",
      "         [ 0.16541079   , -0.10921262   ,  0.08294084   ,\n",
      "           0.004108567  ,  0.04495112   , -0.06777925   ,\n",
      "          -0.1440382    , -0.057616178  ],\n",
      "         [ 0.17140757   ,  0.23613301   , -0.03352245   ,\n",
      "           0.14345543   ,  0.055036142  ,  0.13364553   ,\n",
      "           0.07637279   , -0.09293838   ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.09206569   ,  0.08593938   ,  0.0113394335 ,\n",
      "          -0.0189597    , -0.19843034   ,  0.1378016    ,\n",
      "           0.058517218  , -0.01821535   ],\n",
      "         [ 0.058913335  ,  0.17157048   , -0.09754216   ,\n",
      "           0.021640506  , -0.07641782   , -0.10442652   ,\n",
      "           0.036882438  ,  0.05794965   ],\n",
      "         [-0.066921964  ,  0.07975129   ,  0.20702356   ,\n",
      "          -0.23580343   ,  0.14896983   ,  0.1612075    ,\n",
      "           0.21289755   , -0.027859684  ]],\n",
      "\n",
      "        [[-0.030851584  , -0.09457464   , -0.05899651   ,\n",
      "          -0.13546997   ,  0.005885119  , -0.044293135  ,\n",
      "          -0.0658037    ,  0.002540718  ],\n",
      "         [ 0.076899655  , -0.005129321  , -0.010799924  ,\n",
      "           0.17111863   ,  0.0028151558 , -0.0052444288 ,\n",
      "          -0.0904343    , -0.0069378167 ],\n",
      "         [-0.047486536  ,  0.14069214   ,  0.028753081  ,\n",
      "           0.045820415  ,  0.06053488   ,  0.08103984   ,\n",
      "          -0.0021695404 , -0.027455779  ]],\n",
      "\n",
      "        [[-0.008264313  , -0.14712125   ,  0.10362544   ,\n",
      "          -0.024136724  ,  0.0771713    , -0.15640473   ,\n",
      "           0.016598962  , -0.06914756   ],\n",
      "         [-0.048741505  , -0.019483399  ,  0.047547307  ,\n",
      "          -0.0743436    , -0.061937675  ,  0.0048757917 ,\n",
      "           0.07636491   ,  0.22111468   ],\n",
      "         [ 0.012604065  ,  0.085530624  , -0.049274087  ,\n",
      "          -0.017085152  , -0.11697904   , -0.19606817   ,\n",
      "           0.044710413  ,  0.12993537   ]],\n",
      "\n",
      "        [[-0.08076829   , -0.084538296  , -0.039337467  ,\n",
      "          -0.06405416   , -0.044453457  ,  0.20112464   ,\n",
      "           0.01778018   ,  0.11340182   ],\n",
      "         [ 0.0072588217 ,  0.023467638  ,  0.092094555  ,\n",
      "          -0.09862871   ,  0.046751074  , -0.16370703   ,\n",
      "          -0.10640408   ,  0.06980363   ],\n",
      "         [-0.11249518   ,  0.067309484  ,  0.008287078  ,\n",
      "           0.0036514692 ,  0.15095316   , -0.016638879  ,\n",
      "          -0.048295353  ,  0.13904494   ]]]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(2, 2, 8, 16) dtype=float32, numpy=\n",
      "array([[[[-2.78465927e-01, -7.89889917e-02, -1.08666308e-01,\n",
      "           1.42776435e-02, -4.36147228e-02,  1.48418313e-02,\n",
      "          -1.39952198e-01,  1.18432157e-01,  2.72975266e-01,\n",
      "          -1.92151070e-02,  6.26173466e-02,  7.63714090e-02,\n",
      "          -9.63455290e-02, -6.31445646e-03, -9.73348171e-02,\n",
      "           5.68451993e-02],\n",
      "         [ 1.50620788e-01,  4.25311439e-02, -1.81030929e-01,\n",
      "          -2.20181301e-01,  1.62234873e-01, -5.31266779e-02,\n",
      "           2.21105501e-01,  1.71511814e-01, -2.03397930e-01,\n",
      "           1.76625535e-01,  1.77318349e-01,  5.06255254e-02,\n",
      "           1.28835551e-02,  9.25160870e-02, -7.51984119e-02,\n",
      "           1.08264737e-01],\n",
      "         [ 1.38924718e-01, -2.22239316e-01, -2.12261528e-02,\n",
      "          -2.22538248e-01, -4.11078855e-02, -2.32247896e-02,\n",
      "          -2.09363744e-01,  6.30102530e-02,  1.57695919e-01,\n",
      "           5.04183359e-02, -6.98632300e-02, -6.87018484e-02,\n",
      "          -3.12737405e-01, -7.51011968e-02,  2.34700605e-01,\n",
      "           3.79746854e-02],\n",
      "         [-1.03464589e-01,  1.04551680e-01, -4.25544307e-02,\n",
      "          -2.18211100e-01,  2.81524267e-02,  1.39056280e-01,\n",
      "           2.35987276e-01,  1.16393380e-01, -1.76714435e-01,\n",
      "          -9.31553990e-02,  1.81816518e-01, -1.03646368e-01,\n",
      "          -1.09765930e-02, -2.37686679e-01,  1.52317882e-01,\n",
      "          -3.25480789e-01],\n",
      "         [-3.38131972e-02,  1.75568998e-01,  1.93245187e-01,\n",
      "          -5.36359251e-02, -1.97429284e-01,  3.12383235e-01,\n",
      "           6.81959987e-02,  1.03490338e-01, -1.86477870e-01,\n",
      "          -1.35595605e-01, -3.40076396e-03, -1.26012489e-01,\n",
      "           3.05895675e-02, -6.08667172e-02, -3.27118523e-02,\n",
      "          -1.64548382e-01],\n",
      "         [ 7.41176009e-02,  9.63031128e-02,  4.15658318e-02,\n",
      "           6.37425408e-02, -7.18372166e-02,  2.97180042e-02,\n",
      "           1.08414352e-01, -3.55541743e-02, -8.31962973e-02,\n",
      "           2.19946772e-01,  7.49337599e-02,  8.80339444e-02,\n",
      "           8.41619680e-04, -2.29688153e-01,  7.32024983e-02,\n",
      "          -9.50674042e-02],\n",
      "         [-1.13797113e-01, -2.36777626e-02, -1.77378774e-01,\n",
      "           2.10782290e-01,  2.59902347e-02, -9.66161937e-02,\n",
      "          -1.28993794e-01,  1.31424084e-01, -2.22431332e-01,\n",
      "          -1.52183235e-01,  4.10584733e-04, -1.88947693e-02,\n",
      "          -1.15889087e-01,  4.43381593e-02,  7.71324262e-02,\n",
      "           1.63006298e-02],\n",
      "         [ 2.24260576e-02, -2.08957687e-01, -8.30338523e-02,\n",
      "          -1.45329773e-01,  1.66121736e-01, -1.63403153e-01,\n",
      "           1.23967260e-01, -3.98012288e-02, -5.74054234e-02,\n",
      "           1.25736073e-01,  1.58470556e-01, -1.28416196e-01,\n",
      "           1.34138077e-01,  5.31962737e-02,  3.50997932e-02,\n",
      "          -1.68583900e-01]],\n",
      "\n",
      "        [[ 4.59529422e-02, -2.24144578e-01, -8.54783878e-03,\n",
      "           2.50863228e-02, -4.47062962e-02, -4.52905409e-02,\n",
      "          -1.92613557e-01,  1.87296793e-01, -1.06765367e-01,\n",
      "          -1.51177227e-01, -1.13203712e-01, -5.03629930e-02,\n",
      "          -8.83203447e-02,  6.07102476e-02,  1.15253329e-02,\n",
      "           2.01862473e-02],\n",
      "         [-2.61658847e-01, -2.57291421e-02,  9.17080343e-02,\n",
      "          -1.37574196e-01, -9.65807438e-02,  1.18136011e-01,\n",
      "          -4.98212054e-02, -4.91098203e-02, -3.26569587e-01,\n",
      "          -1.10226506e-02,  2.34288305e-01, -1.70173328e-02,\n",
      "          -8.23800564e-02,  7.29805827e-02,  9.77413058e-02,\n",
      "           1.29489735e-01],\n",
      "         [-3.08184233e-02, -6.65275147e-03,  6.94135129e-02,\n",
      "           6.65355325e-02,  3.19711894e-01,  2.14196667e-01,\n",
      "           2.86257658e-02,  2.13667005e-01,  1.19215637e-01,\n",
      "           1.13470718e-01, -1.77854270e-01,  1.23756684e-01,\n",
      "           1.65850520e-01, -1.91857949e-01, -3.26709077e-02,\n",
      "          -7.54774660e-02],\n",
      "         [ 2.49511041e-02, -7.22135156e-02, -2.16704756e-01,\n",
      "          -8.87048542e-02,  8.46530572e-02,  2.18248501e-01,\n",
      "          -2.31786463e-02,  3.24370489e-02, -4.61724289e-02,\n",
      "           6.75280169e-02,  1.05816990e-01,  5.90807386e-02,\n",
      "           3.19055170e-01, -5.14911413e-02,  2.07669169e-01,\n",
      "          -4.41215597e-02],\n",
      "         [ 9.34605449e-02, -2.44441163e-02,  1.64860293e-01,\n",
      "           3.55682336e-02,  1.93453245e-02, -3.66400965e-02,\n",
      "           2.20484480e-01,  7.29468241e-02,  9.24386382e-02,\n",
      "           4.54083085e-02, -6.74135610e-02,  4.42318339e-03,\n",
      "          -3.14150900e-02, -2.40903005e-01,  1.70709938e-01,\n",
      "           6.11154735e-02],\n",
      "         [ 1.49763063e-01, -2.04725653e-01,  1.06168762e-01,\n",
      "           1.05957761e-01,  9.16633829e-02,  1.67264313e-01,\n",
      "           2.03248598e-02,  1.41339347e-01,  2.44737253e-01,\n",
      "          -1.99274510e-01, -6.53853593e-03, -1.37131453e-01,\n",
      "           1.28479838e-01, -1.50117278e-01, -1.79799035e-01,\n",
      "           1.03248186e-01],\n",
      "         [ 1.55118406e-01,  1.13013452e-02, -4.70634624e-02,\n",
      "          -5.07182218e-02, -2.82458395e-01,  1.56349748e-01,\n",
      "          -8.06453153e-02, -1.09376468e-01, -1.02769740e-01,\n",
      "           1.35446247e-02, -2.46148527e-01,  7.44403452e-02,\n",
      "          -2.02840447e-01, -2.23949909e-01,  2.13722110e-01,\n",
      "           1.48901001e-01],\n",
      "         [ 1.00421995e-01, -7.17219263e-02,  1.43246263e-01,\n",
      "           8.77223760e-02, -4.71263044e-02,  5.54236174e-02,\n",
      "          -8.46508071e-02, -3.16256732e-01,  2.68452987e-03,\n",
      "           8.22217241e-02, -1.80885568e-01, -6.16732053e-02,\n",
      "           2.22204812e-02,  1.74802408e-01, -1.94526047e-01,\n",
      "           1.38805240e-01]]],\n",
      "\n",
      "\n",
      "       [[[ 1.52873054e-01,  1.30755469e-01, -9.76368636e-02,\n",
      "          -1.26459941e-01, -1.12323172e-01, -1.69508532e-02,\n",
      "          -3.01171273e-01,  2.73427635e-01, -7.50006586e-02,\n",
      "          -6.48571039e-03, -1.13466114e-01,  1.19354479e-01,\n",
      "          -2.87990309e-02,  1.23133734e-01,  1.06317215e-01,\n",
      "          -1.44380867e-01],\n",
      "         [ 2.23967284e-01, -1.47874594e-01,  1.12302437e-01,\n",
      "           5.56302583e-03,  6.08641058e-02, -9.17735398e-02,\n",
      "          -1.95028663e-01, -7.80126750e-02,  2.32086942e-01,\n",
      "           3.19725603e-01, -4.53896113e-02,  1.94239587e-01,\n",
      "           7.45192915e-02,  1.80956930e-01,  1.03409253e-01,\n",
      "          -1.25839159e-01],\n",
      "         [ 1.24657542e-01,  1.16362475e-01,  1.53536657e-02,\n",
      "          -2.56715566e-02, -2.68675983e-01,  1.86584264e-01,\n",
      "           7.92326853e-02, -2.46637035e-02,  7.97690377e-02,\n",
      "           2.32307538e-01, -1.32072717e-01,  2.93013826e-02,\n",
      "          -1.03470221e-01, -1.41394183e-01,  4.99390624e-02,\n",
      "           7.84642026e-02],\n",
      "         [-9.06127691e-02,  1.07983761e-01,  2.80311257e-01,\n",
      "          -3.19279373e-01,  2.01706111e-01,  2.18275994e-01,\n",
      "           2.88264662e-01, -3.77221927e-02, -4.17732447e-02,\n",
      "          -1.28054678e-01, -7.98816532e-02, -1.83427215e-01,\n",
      "           7.96848908e-03, -5.99731915e-02, -8.90986398e-02,\n",
      "           3.44014890e-03],\n",
      "         [ 1.04122631e-01, -6.94513414e-03, -1.46231670e-02,\n",
      "           2.31695741e-01,  3.81173915e-03, -7.10099051e-03,\n",
      "          -1.22448623e-01, -9.39384941e-03, -6.42970800e-02,\n",
      "           1.90498069e-01,  3.89318578e-02,  6.20411411e-02,\n",
      "           8.19646195e-02,  1.09728470e-01, -2.93757161e-03,\n",
      "          -3.71753015e-02],\n",
      "         [-1.11899348e-02, -1.99203119e-01,  1.40309513e-01,\n",
      "          -3.26812826e-02,  1.04490444e-01, -2.11773008e-01,\n",
      "           2.24751011e-02, -9.36262459e-02, -6.59963116e-02,\n",
      "          -2.63806488e-02,  6.43793643e-02, -1.00661717e-01,\n",
      "          -8.38640109e-02,  6.60185376e-03,  1.03398591e-01,\n",
      "           2.99390703e-01],\n",
      "         [ 1.70659851e-02,  1.15809016e-01, -6.67174309e-02,\n",
      "          -2.31334064e-02, -1.58390388e-01, -2.65477568e-01,\n",
      "           6.05381876e-02,  1.75933331e-01, -1.09360777e-01,\n",
      "          -1.14465393e-01, -5.32631837e-02, -8.67297500e-02,\n",
      "          -6.01902679e-02,  2.72324055e-01,  2.40744762e-02,\n",
      "           1.53546795e-01],\n",
      "         [ 9.82849114e-03,  3.17753330e-02,  1.24696620e-01,\n",
      "          -1.33543909e-01,  6.33012578e-02, -2.21660390e-01,\n",
      "          -1.44071817e-01,  9.45145711e-02, -1.52319193e-01,\n",
      "           9.11374763e-02,  1.12207560e-02,  4.94411308e-03,\n",
      "           2.04391539e-01, -2.25291494e-02, -6.53922185e-02,\n",
      "           1.88267738e-01]],\n",
      "\n",
      "        [[ 1.36028588e-01,  2.05886692e-01, -8.97904411e-02,\n",
      "          -3.10922027e-01,  7.89567232e-02, -7.71334991e-02,\n",
      "          -2.00146839e-01, -1.67714566e-01, -1.94247648e-01,\n",
      "          -2.05872178e-01,  5.34895435e-02,  2.56740097e-02,\n",
      "          -2.24594384e-01,  1.96826860e-01, -1.12957291e-01,\n",
      "           5.71217760e-02],\n",
      "         [ 1.84962913e-01, -1.72946587e-01, -2.24621922e-01,\n",
      "          -1.93902315e-03, -1.25944808e-01,  2.98748761e-02,\n",
      "          -2.33203277e-01, -2.39619136e-01,  1.47715837e-01,\n",
      "           9.27779078e-02,  1.62289888e-02,  2.45360255e-01,\n",
      "          -1.25886917e-01, -3.24138969e-01, -2.14035362e-01,\n",
      "          -1.78230852e-01],\n",
      "         [ 8.56922418e-02,  8.84396583e-02,  6.39314801e-02,\n",
      "           2.55712997e-02, -1.74668044e-01,  1.81357712e-01,\n",
      "          -1.08971544e-01,  3.61357965e-02,  3.32400426e-02,\n",
      "           8.35403055e-02, -2.98693627e-02,  2.20960930e-01,\n",
      "           3.48063477e-05,  4.22834791e-02,  2.35574931e-01,\n",
      "          -1.90914825e-01],\n",
      "         [ 9.81988758e-02,  2.15385988e-01, -7.75405541e-02,\n",
      "          -4.81438972e-02, -2.57112205e-01,  1.55172884e-01,\n",
      "           5.84214702e-02, -1.51449218e-02,  1.21001437e-01,\n",
      "           4.36935574e-03,  3.14341843e-01,  1.25078466e-02,\n",
      "          -4.49473336e-02,  2.72208035e-01,  1.90702975e-01,\n",
      "          -2.64480948e-01],\n",
      "         [-1.84780598e-01,  8.19126144e-02, -2.40626425e-01,\n",
      "           2.47351732e-02, -7.00756982e-02,  7.81959221e-02,\n",
      "          -2.54835904e-01, -1.81502160e-02, -9.90428403e-02,\n",
      "          -1.94199961e-02, -2.50550896e-01,  2.55718231e-01,\n",
      "          -1.75842214e-02, -1.82612240e-01,  2.93796556e-03,\n",
      "           4.68275249e-02],\n",
      "         [-7.79614896e-02,  1.77028209e-01,  5.72450161e-02,\n",
      "           1.92658707e-01, -4.25690636e-02, -8.39906372e-03,\n",
      "           2.08323717e-01,  1.69859510e-02,  1.14010178e-01,\n",
      "          -3.07268769e-01,  1.33462682e-01,  2.44424999e-01,\n",
      "          -1.85420766e-01,  5.97581305e-02,  8.41269717e-02,\n",
      "          -2.94051200e-01],\n",
      "         [-2.88664587e-02,  4.13364656e-02,  1.92308724e-01,\n",
      "          -5.64409010e-02, -2.14460626e-01, -1.12880953e-01,\n",
      "           2.48136684e-01,  3.94215658e-02,  4.11437713e-02,\n",
      "          -2.11013541e-01,  1.51983544e-01, -5.97097315e-02,\n",
      "          -1.80072069e-01, -6.68572783e-02,  2.98719611e-02,\n",
      "           2.79916435e-01],\n",
      "         [-1.21953152e-01,  6.55134544e-02, -5.29112816e-02,\n",
      "          -3.01660635e-02, -3.51972096e-02,  3.26199204e-01,\n",
      "          -1.27366140e-01, -9.80949476e-02, -2.23230440e-02,\n",
      "           4.26757336e-02,  3.07222139e-02, -1.28377691e-01,\n",
      "           2.13548377e-01, -1.12518549e-01, -1.86893642e-02,\n",
      "           1.13192096e-01]]]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(6, 64) dtype=float32, numpy=\n",
      "array([[-0.3261059    , -0.09250244   , -0.12725694   ,  0.016720263  ,\n",
      "        -0.051076334  ,  0.017380973  , -0.16389523   ,  0.13869354   ,\n",
      "         0.3196759    , -0.022502428  ,  0.07332993   ,  0.08943704   ,\n",
      "        -0.11282833   , -0.0073947343 , -0.113986865  ,  0.06657028   ,\n",
      "         0.176389     ,  0.049807377  , -0.21200171   , -0.25784993   ,\n",
      "         0.18999003   , -0.062215593  ,  0.25893226   ,  0.20085406   ,\n",
      "        -0.23819526   ,  0.20684265   ,  0.20765398   ,  0.059286546  ,\n",
      "         0.015087674  ,  0.10834375   , -0.08806336   ,  0.12678668   ,\n",
      "         0.16269197   , -0.26026005   , -0.024857525  , -0.2606101    ,\n",
      "        -0.048140626  , -0.02719809   , -0.24518171   ,  0.07379006   ,\n",
      "         0.18467456   ,  0.05904391   , -0.08181544   , -0.08045536   ,\n",
      "        -0.36624053   , -0.087949514  ,  0.2748532    ,  0.044471398  ,\n",
      "        -0.12116532   ,  0.12243839   , -0.04983465   , -0.25554267   ,\n",
      "         0.03296875   ,  0.16284604   ,  0.27636      ,  0.13630597   ,\n",
      "        -0.20694676   , -0.10909244   ,  0.21292171   , -0.1213782    ,\n",
      "        -0.01285447   , -0.27835014   ,  0.17837644   , -0.38116407   ],\n",
      "       [-0.039597962  ,  0.20560536   ,  0.22630559   , -0.06281196   ,\n",
      "        -0.23120551   ,  0.36582577   ,  0.079862975  ,  0.12119547   ,\n",
      "        -0.21838053   , -0.15879332   , -0.0039825668 , -0.14757071   ,\n",
      "         0.035822835  , -0.0712798    , -0.0383082    , -0.19269933   ,\n",
      "         0.08679765   ,  0.112778656  ,  0.04867692   ,  0.07464762   ,\n",
      "        -0.08412713   ,  0.03480216   ,  0.12696189   , -0.041636787  ,\n",
      "        -0.09742952   ,  0.25757527   ,  0.08775343   ,  0.103094794  ,\n",
      "         0.000985604  , -0.26898322   ,  0.085725985  , -0.111331545  ,\n",
      "        -0.13326553   , -0.027728556  , -0.20772474   ,  0.24684294   ,\n",
      "         0.030436646  , -0.1131453    , -0.15106206   ,  0.15390813   ,\n",
      "        -0.2604849    , -0.17821875   ,  0.00048082758, -0.02212729   ,\n",
      "        -0.1357154    ,  0.051923536  ,  0.09032825   ,  0.019089343  ,\n",
      "         0.026262708  , -0.2447062    , -0.097239286  , -0.17019281   ,\n",
      "         0.19454184   , -0.19135818   ,  0.14517559   , -0.046610426  ,\n",
      "        -0.06722634   ,  0.147247     ,  0.18558171   , -0.15038565   ,\n",
      "         0.15708643   ,  0.0622971    ,  0.041104667  , -0.19742525   ],\n",
      "       [ 0.053814575  , -0.26249126   , -0.010010204  ,  0.029378092  ,\n",
      "        -0.052354652  , -0.05303885   , -0.2255659    ,  0.21933955   ,\n",
      "        -0.12503079   , -0.17704065   , -0.13257061   , -0.058979098  ,\n",
      "        -0.1034302    ,  0.07109656   ,  0.013497087  ,  0.02363971   ,\n",
      "        -0.30642346   , -0.030130886  ,  0.10739745   , -0.1611104    ,\n",
      "        -0.113103785  ,  0.13834673   , -0.05834462   , -0.057511535  ,\n",
      "        -0.38243914   , -0.012908407  ,  0.27437037   , -0.01992866   ,\n",
      "        -0.09647364   ,  0.0854661    ,  0.1144629    ,  0.15164284   ,\n",
      "        -0.036090843  , -0.007790905  ,  0.081288785  ,  0.07791844   ,\n",
      "         0.37440822   ,  0.25084144   ,  0.033523064  ,  0.2502212    ,\n",
      "         0.13961105   ,  0.1328833    , -0.2082816    ,  0.14492899   ,\n",
      "         0.19422424   , -0.22468103   , -0.038260248  , -0.08839016   ,\n",
      "         0.029219741  , -0.084567815  , -0.25377864   , -0.10388049   ,\n",
      "         0.0991355    ,  0.25558648   , -0.02714405   ,  0.037986383  ,\n",
      "        -0.054071613  ,  0.079080716  ,  0.123920165  ,  0.06918828   ,\n",
      "         0.37363917   , -0.06030025   ,  0.24319723   , -0.05166988   ],\n",
      "       [ 0.10944978   , -0.02862602   ,  0.19306462   ,  0.04165325   ,\n",
      "         0.022654925  , -0.04290849   ,  0.25820497   ,  0.08542657   ,\n",
      "         0.10825305   ,  0.053176764  , -0.07894668   ,  0.0051799016 ,\n",
      "        -0.03678959   , -0.2821167    ,  0.19991502   ,  0.07157111   ,\n",
      "         0.17538455   , -0.23975013   ,  0.12433212   ,  0.12408502   ,\n",
      "         0.107345164  ,  0.1958799    ,  0.023802038  ,  0.1655197    ,\n",
      "         0.2866069    , -0.23336641   , -0.0076571493 , -0.16059192   ,\n",
      "         0.15046017   , -0.17579935   , -0.21055907   ,  0.12091189   ,\n",
      "         0.18165606   ,  0.01323478   , -0.055115085  , -0.059395097  ,\n",
      "        -0.33078137   ,  0.18309808   , -0.09444212   , -0.12808861   ,\n",
      "        -0.1203516    ,  0.01586184   , -0.28825963   ,  0.08717561   ,\n",
      "        -0.23754242   , -0.26226327   ,  0.2502857    ,  0.17437498   ,\n",
      "         0.1176022    , -0.083992116  ,  0.16775285   ,  0.102729924  ,\n",
      "        -0.055188674  ,  0.064905494  , -0.09913287   , -0.37036195   ,\n",
      "         0.0031437995 ,  0.09628823   , -0.21183148   , -0.07222427   ,\n",
      "         0.026021963  ,  0.20470761   , -0.22780557   ,  0.16255206   ],\n",
      "       [ 0.17902659   ,  0.15312514   , -0.11434058   , -0.14809471   ,\n",
      "        -0.13153943   , -0.019850805  , -0.35269567   ,  0.32020566   ,\n",
      "        -0.08783177   , -0.0075952862 , -0.1328779    ,  0.13977365   ,\n",
      "        -0.033725973  ,  0.14419946   ,  0.12450597   , -0.16908157   ,\n",
      "         0.26228362   , -0.173173     ,  0.13151515   ,  0.0065147486 ,\n",
      "         0.07127674   , -0.10747416   , -0.22839418   , -0.091359094  ,\n",
      "         0.27179238   ,  0.3744243    , -0.05315487   ,  0.22747011   ,\n",
      "         0.08726806   ,  0.21191506   ,  0.121100515  , -0.14736773   ,\n",
      "         0.14598396   ,  0.13626978   ,  0.017980373  , -0.030063448  ,\n",
      "        -0.3146411    ,  0.21850511   ,  0.092787825  , -0.028883172  ,\n",
      "         0.09341593   ,  0.27205074   , -0.15466772   ,  0.034314267  ,\n",
      "        -0.121171914  , -0.16558391   ,  0.05848264   ,  0.09188786   ,\n",
      "        -0.10611481   ,  0.12645763   ,  0.32826692   , -0.37390172   ,\n",
      "         0.23621401   ,  0.25561866   ,  0.337581     , -0.044175707  ,\n",
      "        -0.04891981   , -0.14996228   , -0.09354781   , -0.21480796   ,\n",
      "         0.009331739  , -0.07023341   , -0.10434164   ,  0.0040286896 ],\n",
      "       [ 0.12193594   , -0.008133308  , -0.017124899  ,  0.27133426   ,\n",
      "         0.004463852  , -0.008315829  , -0.14339714   , -0.01100095   ,\n",
      "        -0.07529703   ,  0.2230885    ,  0.045592323  ,  0.07265514   ,\n",
      "         0.09598713   ,  0.12850082   , -0.0034401317 , -0.043535255  ,\n",
      "        -0.013104309  , -0.2332828    ,  0.16431369   , -0.0382724    ,\n",
      "         0.12236668   , -0.24800315   ,  0.026320145  , -0.10964383   ,\n",
      "        -0.077286966  , -0.030893851  ,  0.075393386  , -0.11788293   ,\n",
      "        -0.098211475  ,  0.0077312994 ,  0.12108803   ,  0.3506105    ,\n",
      "         0.019985635  ,  0.13562162   , -0.07813146   , -0.027091071  ,\n",
      "        -0.18548782   , -0.3108955    ,  0.07089507   ,  0.20603201   ,\n",
      "        -0.12807024   , -0.13404815   , -0.062375452  , -0.101567484  ,\n",
      "        -0.07048762   ,  0.31891328   ,  0.02819314   ,  0.17981559   ,\n",
      "         0.01150995   ,  0.03721146   ,  0.14602973   , -0.1563906    ,\n",
      "         0.07413084   , -0.25958207   , -0.16871963   ,  0.11068413   ,\n",
      "        -0.17837797   ,  0.106729284  ,  0.013140405  ,  0.0057899524 ,\n",
      "         0.23935887   , -0.026383437  , -0.076579526  ,  0.2204766    ]],\n",
      "      dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "listp_test = initialize_parameters_CNN_2layers()\n",
    "print (listp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Forward propagation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward_list_CNN_3layers (X, listp):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Note that for simplicity and grading purposes, we'll hard-code some values\n",
    "    such as the stride and kernel (filter) sizes. \n",
    "    Normally, functions should take these values as function parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = listp[0]\n",
    "    W2 = listp[1]\n",
    "    W3 = listp[2]\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "    # FLATTEN\n",
    "    flatten_layer = tf.keras.layers.Flatten()  # instantiate the layer\n",
    "    F = flatten_layer(P2)                      # call it on the given tensor\n",
    "    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "    Z3 = tf.matmul(W3, tf.transpose(F))\n",
    "\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_test shape:  (10, 4)\n",
      "W_test shape:  (3, 4)\n",
      "Z_test shape:  (3, 10)\n"
     ]
    }
   ],
   "source": [
    "F_test = tf.constant([[3.2, 4.01, 4.85, 7.32], [3.2, 4.01, 4.85, 7.32], [3.63, 9.1,5.45,6.41],  [4.2, 7.12, 0.,5.1],[3.2, 4.01, 4.85, 7.32], [3.63, 9.1,5.45,6.41],  [4.2, 7.12, 0.,5.1], [5.5, 7.12, 0.,5.1], [5.2, 7.12, 0.,5.1], [4.9, 7.12, 0.,5.1]])\n",
    "W_test = tf.constant([[-0.03269102, 7.12, 0.,5.1], [-0.02149617, 7.12, 0.,5.1], [-0.04413767, 7.12, 0.,5.1]])\n",
    "print(\"F_test shape: \", F_test.shape)\n",
    "print(\"W_test shape: \", W_test.shape)\n",
    "Z_test = tf.matmul(W_test, tf.transpose (F_test))\n",
    "print(\"Z_test shape: \", Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_CNN (ZL, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    method: softmax_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "   \n",
    "    #compute softmax\n",
    "    cost = tf.nn.softmax(tf.transpose(ZL), axis= 1)\n",
    "   \n",
    "    #compute cross_entropy\n",
    "    cost = -tf.reduce_mean(tf.reduce_sum(Y * tf.math.log(cost),1))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_test shape:  (10, 4)\n",
      "F_test:  tf.Tensor(\n",
      "[[0.1  0.1  0.1  0.1 ]\n",
      " [0.   4.01 4.85 7.32]\n",
      " [0.   9.1  5.45 6.41]\n",
      " [0.   7.12 0.   5.1 ]\n",
      " [3.2  4.01 4.85 7.32]\n",
      " [3.63 9.1  5.45 6.41]\n",
      " [4.2  7.12 0.   5.1 ]\n",
      " [5.5  7.12 0.   5.1 ]\n",
      " [5.2  7.12 0.   5.1 ]\n",
      " [4.9  7.12 0.   5.1 ]], shape=(10, 4), dtype=float32)\n",
      "S_test(sum):  tf.Tensor(\n",
      "[4.4206839e+00 1.6940916e+03 9.7969473e+03 1.4024722e+03 1.7176240e+03\n",
      " 9.8336602e+03 1.4681584e+03 1.6461641e+03 1.5827444e+03 1.5357620e+03], shape=(10,), dtype=float32)\n",
      "Q_test:  tf.Tensor(\n",
      "[[2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [5.90286858e-04 3.25524807e-02 7.54034668e-02 8.91453743e-01]\n",
      " [1.02072612e-04 9.14090455e-01 2.37582289e-02 6.20492846e-02]\n",
      " [7.13026617e-04 8.81622016e-01 7.13026617e-04 1.16951980e-01]\n",
      " [1.42828301e-02 3.21064927e-02 7.43703991e-02 8.79240274e-01]\n",
      " [3.83507484e-03 9.10677791e-01 2.36695297e-02 6.18176274e-02]\n",
      " [4.54217456e-02 8.42177689e-01 6.81125384e-04 1.11719482e-01]\n",
      " [1.48643702e-01 7.51110017e-01 6.07472844e-04 9.96388495e-02]\n",
      " [1.14530317e-01 7.81206548e-01 6.31813949e-04 1.03631325e-01]\n",
      " [8.74418020e-02 8.05105448e-01 6.51142560e-04 1.06801637e-01]], shape=(10, 4), dtype=float32)\n",
      "Q_test:  tf.Tensor(\n",
      "[ 0.        0.        0.       16.763968  0.       12.184265  0.\n",
      " 11.904813 -0.       12.227128], shape=(10,), dtype=float32)\n",
      "Q_test:  tf.Tensor(5.3080173, shape=(), dtype=float32)\n",
      "softmax_test:  tf.Tensor(\n",
      "[[2.50000000e-01 2.50000000e-01 2.50000000e-01 2.50000000e-01]\n",
      " [5.90286858e-04 3.25524807e-02 7.54034668e-02 8.91453743e-01]\n",
      " [1.02072612e-04 9.14090455e-01 2.37582289e-02 6.20492883e-02]\n",
      " [7.13026617e-04 8.81622016e-01 7.13026617e-04 1.16951987e-01]\n",
      " [1.42828329e-02 3.21064927e-02 7.43703917e-02 8.79240274e-01]\n",
      " [3.83507484e-03 9.10677850e-01 2.36695316e-02 6.18176386e-02]\n",
      " [4.54217419e-02 8.42177629e-01 6.81125326e-04 1.11719474e-01]\n",
      " [1.48643702e-01 7.51109958e-01 6.07472786e-04 9.96388420e-02]\n",
      " [1.14530317e-01 7.81206608e-01 6.31813949e-04 1.03631333e-01]\n",
      " [8.74418020e-02 8.05105448e-01 6.51142560e-04 1.06801644e-01]], shape=(10, 4), dtype=float32)\n",
      "cost_test:  tf.Tensor(\n",
      "[ 0.        0.        0.       16.763968  0.       12.184265  0.\n",
      " 11.904813  0.       12.227128], shape=(10,), dtype=float32)\n",
      "cost_test:  tf.Tensor(5.3080173, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test softmax_cross_entropy_with_logits\n",
    "\n",
    "F_test = tf.constant([[0.1, 0.1, 0.1, 0.1], [0, 4.01, 4.85, 7.32], [0, 9.1,5.45,6.41],  [0, 7.12, 0.,5.1],[3.2, 4.01, 4.85, 7.32], [3.63, 9.1,5.45,6.41],  [4.2, 7.12, 0.,5.1], [5.5, 7.12, 0.,5.1], [5.2, 7.12, 0.,5.1], [4.9, 7.12, 0.,5.1]])\n",
    "labels_test = tf.constant([[0.], [0.], [0.],  [1.],[0.], [1.],  [0.], [1.], [0.], [1.]])\n",
    "\n",
    "print(\"F_test shape: \", F_test.shape)\n",
    "print(\"F_test: \", F_test)\n",
    "\n",
    "S_test = tf.math.reduce_sum(tf.math.exp(F_test),axis=1)\n",
    "print(\"S_test(sum): \", S_test)\n",
    "Q_test = tf.math.divide(tf.math.exp(F_test),tf.reshape(S_test, (-1, 1)))\n",
    "print(\"Q_test: \", Q_test)\n",
    "Q_test = -tf.reduce_sum(labels_test * tf.math.log(Q_test),1)\n",
    "print(\"Q_test: \", Q_test)\n",
    "Q_test= tf.reduce_mean(Q_test)\n",
    "print(\"Q_test: \", Q_test)\n",
    "softmax_test = tf.nn.softmax(F_test,axis= 1)\n",
    "print(\"softmax_test: \", softmax_test)\n",
    "\n",
    "cost_test = tf.nn.softmax_cross_entropy_with_logits(logits = F_test, labels = labels_test)\n",
    "print(\"cost_test: \", cost_test)\n",
    "cost_test= tf.reduce_mean(cost_test)\n",
    "print(\"cost_test: \", cost_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches_CNN(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_tf_CNN_3Layers(X, Y, learning_rate = 0.0075, num_epochs = 1500, minibatch_size = 32, print_cost = True, lambd = 0., ADAM = False):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if ADAM:\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.999\n",
    "        epsilon = 1e-4\n",
    "    else:    \n",
    "        beta1 = 0\n",
    "        beta2 = 0\n",
    "        epsilon = 0 \n",
    "        \n",
    "    print (\"learning_rate:\" + str(learning_rate)) \n",
    "    print (\"minibatch_size:\" + str(minibatch_size)) \n",
    "    print (\"num_epochs:\" + str(num_epochs)) \n",
    "    print (\"lambd:\" + str(lambd)) \n",
    "    #print (\"keep_prob:\" + str(keep_prob)) \n",
    "    print (\"beta1:\" + str(beta1)) \n",
    "    print (\"beta2:\" + str(beta2)) \n",
    "    print (\"epsilon:\" + str(epsilon))\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.random.set_seed(1)                             # to keep consistent results\n",
    "    seed = 1                                          # to keep consistent results\n",
    "    \n",
    "    (m, n_H0, n_W0, n_C0) = X.shape             \n",
    "    n_y = Y.shape[1]                          # n_y : output size\n",
    "\n",
    "    print (\"m:\" + str(m))\n",
    "    print (\"n_H0:\" + str(n_H0))\n",
    "    print (\"n_W0:\" + str(n_W0))\n",
    "    print (\"n_C0:\" + str(n_C0))    \n",
    "    print (\"n_y:\" + str(n_y))\n",
    "    costs = []\n",
    "    \n",
    "    # Initialize parameters\n",
    "    listp = initialize_parameters_CNN_2layers()  #2 layers en dur\n",
    "    \n",
    "    if ADAM:\n",
    "        optimizer = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=beta1, beta_2=beta2, epsilon=epsilon)\n",
    "    else:   \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "       \n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            c = 0.\n",
    "            seed = seed + 1\n",
    "         \n",
    "            # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch          \n",
    "            minibatches = random_mini_batches_CNN(X, Y, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                mini_m = minibatch_X.shape[1]\n",
    "                    \n",
    "                with tf.GradientTape() as tape:\n",
    "                     ZL = L_model_forward_list_CNN_3layers (minibatch_X, listp)\n",
    "                     #print (\"ZL: \" +str(ZL))                      \n",
    "                     \n",
    "                     loss_value= compute_cost_CNN (ZL, minibatch_Y)\n",
    "                     #print (\"loss_value: \" +str(loss_value)) \n",
    "                        \n",
    "                grads = tape.gradient(loss_value, listp)\n",
    "                #print (\"grads: \" +str(grads))\n",
    "                grads_and_vars = zip(grads, listp)\n",
    "                optimizer.apply_gradients(grads_and_vars)             \n",
    "                \n",
    "                epoch_cost += loss_value\n",
    "                c = c + 1\n",
    "\n",
    "            epoch_cost = epoch_cost / c\n",
    "            \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "             \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per fives)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "        \n",
    "    return listp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_signs():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = load_dataset_signs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos (X):\n",
    "    Q = X[:, 0:1]\n",
    "    print (\"0 shape: \" + str(Q.shape))\n",
    "    print (\"0 average: \" + str(np.average(Q)))\n",
    "    print (\"0 std: \" + str(np.std(Q)))\n",
    "    print (\"0: \" + str(Q))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-824fae173075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_orig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"y = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y_orig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\". It's a \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_y_orig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m\" picture.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'decode'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 10\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y_orig[0,index]) + \". It's a \" + classes[train_y_orig[0,index]].decode(\"utf-8\") +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "train_x shape: (1080, 64, 64, 3)\n",
      "train_x dtype: float32\n",
      "train_y shape: (1080, 6)\n",
      "train_y dtype: float32\n",
      "test_x shape: (120, 64, 64, 3)\n",
      "test_y shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x_orig.astype(np.float32)/255.\n",
    "test_x = test_x_orig.astype(np.float32)/255.\n",
    "train_y = convert_to_one_hot(train_y_orig, 6).T\n",
    "train_y = train_y.astype(np.float32)\n",
    "test_y = convert_to_one_hot(test_y_orig, 6).T\n",
    "test_y = test_y.astype(np.float32)\n",
    "print (\"number of training examples = \" + str(train_x.shape[0]))\n",
    "print (\"number of test examples = \" + str(test_x.shape[0]))\n",
    "print (\"train_x shape: \" + str(train_x.shape))\n",
    "print (\"train_x dtype: \" + str(train_x.dtype))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"train_y dtype: \" + str(train_y.dtype))\n",
    "print (\"test_x shape: \" + str(test_x.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate:0.009\n",
      "minibatch_size:64\n",
      "num_epochs:100\n",
      "lambd:0.0\n",
      "beta1:0.9\n",
      "beta2:0.999\n",
      "epsilon:0.0001\n",
      "m:1080\n",
      "n_H0:64\n",
      "n_W0:64\n",
      "n_C0:3\n",
      "n_y:6\n",
      "Cost after epoch 0: 1.802190\n",
      "Cost after epoch 10: 1.007048\n",
      "Cost after epoch 20: 0.709725\n",
      "Cost after epoch 30: 0.520906\n",
      "Cost after epoch 40: 0.456905\n",
      "Cost after epoch 50: 0.376530\n",
      "Cost after epoch 60: 0.375832\n",
      "Cost after epoch 70: 0.329991\n",
      "Cost after epoch 80: 0.267324\n",
      "Cost after epoch 90: 0.296682\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=15)\n",
    "listp = model_tf_CNN_3Layers(train_x, train_y, learning_rate = 0.009, num_epochs = 100, minibatch_size = 64, print_cost = True, lambd = 0., ADAM = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tf_CNN_3layers(X, Y, listp):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "   \n",
    "    # Forward propagation\n",
    "    ZL = L_model_forward_list_CNN_3layers (X, listp)\n",
    "    \n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(ZL, 0)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    " \n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train:  tf.Tensor(0.9037037, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = predict_tf_CNN_3layers(train_x, train_y, listp)\n",
    "print(\"accuracy train: \",str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test:  tf.Tensor(0.725, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = predict_tf_CNN_3layers(test_x, test_y, listp)\n",
    "print(\"accuracy test: \",str(accuracy_test))  "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "c4HO0",
   "launcher_item_id": "lSYZM"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
